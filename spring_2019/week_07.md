Conitnued to implement skipgram model.
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/word2vec/word2vec_basic.py
http://www.thushv.com/natural_language_processing/word2vec-part-1-nlp-with-deep-learning-with-tensorflow-skip-gram/
are my sources for some of my motivation.
There will have to be optimization in the parameters for my model.
These parameters are "batchsize,numskips, and skipwindow" and I need to look into the performace and accuracy differences in small vs large data sets with these parameters.
I have also become much more familiar with google's tensorflow.

This coming week will be finalizing my implementation for skip-gram.
As usual my blocks tend to be my lack of understand in probability theory and the softmax function.
 
